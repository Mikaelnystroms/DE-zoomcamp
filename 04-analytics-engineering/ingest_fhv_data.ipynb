{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded fhv_tripdata_2019_1.csv.gz\n",
      "Downloaded fhv_tripdata_2019_2.csv.gz\n",
      "Downloaded fhv_tripdata_2019_3.csv.gz\n",
      "Downloaded fhv_tripdata_2019_4.csv.gz\n",
      "Downloaded fhv_tripdata_2019_5.csv.gz\n",
      "Downloaded fhv_tripdata_2019_6.csv.gz\n",
      "Downloaded fhv_tripdata_2019_7.csv.gz\n",
      "Downloaded fhv_tripdata_2019_8.csv.gz\n",
      "Downloaded fhv_tripdata_2019_9.csv.gz\n",
      "Downloaded fhv_tripdata_2019_10.csv.gz\n",
      "Downloaded fhv_tripdata_2019_11.csv.gz\n",
      "Downloaded fhv_tripdata_2019_12.csv.gz\n"
     ]
    }
   ],
   "source": [
    "for month in range(1, 13):  # Loop from January (1) to December (12)\n",
    "    base_url = f\"https://github.com/DataTalksClub/nyc-tlc-data/releases/download/fhv/fhv_tripdata_2019-{month:02d}.csv.gz\"\n",
    "    url = base_url.format(month=month)\n",
    "    response = requests.get(base_url)\n",
    "    if response.status_code == 200:\n",
    "        filename = f\"fhv_tripdata_2019_{month}.csv.gz\"\n",
    "        with open(filename, \"wb\") as f:\n",
    "            f.write(response.content)\n",
    "        print(f\"Downloaded {filename}\")\n",
    "    else:\n",
    "        print(f\"Failed to download data for month {month:02d}: HTTP {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "# Get a list of all CSV files in a directory\n",
    "csv_files = glob.glob('*.csv.gz')\n",
    "\n",
    "# Create an empty dataframe to store the combined data\n",
    "combined_df = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file and append its contents to the combined dataframe\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, compression='gzip')\n",
    "    combined_df = pd.concat([combined_df, df])\n",
    "\n",
    "# Print the combined dataframe\n",
    "print(combined_df)\n",
    "combined_df.to_csv('fhv_data_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded fhv_tripdata_2019_1.csv.gz to taxi_2019_2020.\n",
      "Uploaded fhv_tripdata_2019_2.csv.gz to taxi_2019_2020.\n",
      "Uploaded fhv_tripdata_2019_3.csv.gz to taxi_2019_2020.\n",
      "Uploaded fhv_tripdata_2019_4.csv.gz to taxi_2019_2020.\n",
      "Uploaded fhv_tripdata_2019_5.csv.gz to taxi_2019_2020.\n",
      "Uploaded fhv_tripdata_2019_6.csv.gz to taxi_2019_2020.\n",
      "Uploaded fhv_tripdata_2019_7.csv.gz to taxi_2019_2020.\n",
      "Uploaded fhv_tripdata_2019_8.csv.gz to taxi_2019_2020.\n",
      "Uploaded fhv_tripdata_2019_9.csv.gz to taxi_2019_2020.\n",
      "Uploaded fhv_tripdata_2019_10.csv.gz to taxi_2019_2020.\n",
      "Uploaded fhv_tripdata_2019_11.csv.gz to taxi_2019_2020.\n",
      "Uploaded fhv_tripdata_2019_12.csv.gz to taxi_2019_2020.\n"
     ]
    }
   ],
   "source": [
    "from google.cloud.storage import Client, transfer_manager\n",
    "\n",
    "def upload_many_blobs_with_transfer_manager(filenames, bucket_name=\"taxi_2019_2020\", source_directory=\"\", workers=8):\n",
    "    \"\"\"Upload every file in a list to a bucket, concurrently in a process pool.\"\"\"\n",
    "\n",
    "    storage_client = Client()\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "\n",
    "    results = transfer_manager.upload_many_from_filenames(\n",
    "        bucket, filenames, source_directory=source_directory, max_workers=workers\n",
    "    )\n",
    "\n",
    "    for name, result in zip(filenames, results):\n",
    "        if isinstance(result, Exception):\n",
    "            print(f\"Failed to upload {name} due to exception: {result}\")\n",
    "        else:\n",
    "            print(f\"Uploaded {name} to {bucket.name}.\")\n",
    "\n",
    "# Create a flat list of filenames\n",
    "filenames = [f\"fhv_tripdata_2019_{month}.csv.gz\" for month in range(1, 13)]\n",
    "\n",
    "# Call the function with the corrected filenames list\n",
    "upload_many_blobs_with_transfer_manager(filenames=filenames, bucket_name=\"taxi_2019_2020\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Initialize a BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Define your dataset and table\n",
    "dataset_id = 'trips_data_all'\n",
    "table_id = 'fhv_data'\n",
    "\n",
    "# The table where you want to append the data\n",
    "table_ref = client.dataset(dataset_id).table(table_id)\n",
    "\n",
    "# Configure the load job to append the data to the existing table\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    source_format=bigquery.SourceFormat.CSV,\n",
    "    skip_leading_rows=1,  # Assuming your CSV files have a header row\n",
    "    autodetect=False,  # Detect schema automatically for the first file\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_APPEND,  # Append to the table\n",
    ")\n",
    "\n",
    "# The URL to the files in Google Cloud Storage, using a wildcard for the months\n",
    "uri = \"gs://taxi_2019_2020/fhv_tripdata_2019_*.csv.gz\"\n",
    "\n",
    "# Start the load job\n",
    "load_job = client.load_table_from_uri(\n",
    "    uri,\n",
    "    table_ref,\n",
    "    job_config=job_config\n",
    ")\n",
    "\n",
    "# Wait for the load job to complete\n",
    "load_job.result()\n",
    "\n",
    "print(f\"Data from {uri} appended to {dataset_id}.{table_id}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
